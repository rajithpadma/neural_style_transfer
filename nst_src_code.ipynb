{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a510e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Function to load and preprocess an image\n",
    "def load_and_process_image(image_path, max_dim=512):\n",
    "    img = Image.open(image_path)\n",
    "    long = max(img.size)\n",
    "    scale = max_dim / long\n",
    "    img = img.resize((int(img.size[0] * scale), int(img.size[1] * scale)))\n",
    "    img = np.expand_dims(np.array(img), axis=0)\n",
    "    return tf.keras.applications.mobilenet_v2.preprocess_input(img)\n",
    "\n",
    "# Function to deprocess an image\n",
    "def deprocess_image(img):\n",
    "    img = img[0]\n",
    "    img = (img + 1.0) * 127.5  # Reverse MobileNetV2 preprocessing\n",
    "    return np.clip(img, 0, 255).astype('uint8')\n",
    "\n",
    "# Load content and style images\n",
    "content_path = \"content.jpg\"  # Path to content image\n",
    "style_path = \"style.jpg\"      # Path to style image\n",
    "\n",
    "content_image = load_and_process_image(content_path)\n",
    "style_image = load_and_process_image(style_path)\n",
    "\n",
    "# Load pre-trained MobileNetV2 model\n",
    "mobilenet = MobileNetV2(include_top=False, weights='imagenet')\n",
    "mobilenet.trainable = False\n",
    "\n",
    "# Define layers for content and style\n",
    "content_layers = ['block_13_expand_relu']  # Adapted for MobileNetV2\n",
    "style_layers = [\n",
    "    'block_1_expand_relu', 'block_3_expand_relu', \n",
    "    'block_5_expand_relu', 'block_7_expand_relu', \n",
    "    'block_9_expand_relu'\n",
    "]\n",
    "\n",
    "def get_model():\n",
    "    outputs = [mobilenet.get_layer(name).output for name in style_layers + content_layers]\n",
    "    return Model([mobilenet.input], outputs)\n",
    "\n",
    "# Define loss functions\n",
    "def gram_matrix(input_tensor):\n",
    "    channels = int(input_tensor.shape[-1])\n",
    "    vectorized = tf.reshape(input_tensor, [-1, channels])\n",
    "    return tf.matmul(vectorized, vectorized, transpose_a=True)\n",
    "\n",
    "def compute_loss(outputs, content_target, style_target, style_weight=1e-2, content_weight=1e4):\n",
    "    style_outputs, content_outputs = outputs[:-1], outputs[-1]\n",
    "    style_loss = tf.add_n([tf.reduce_mean((gram_matrix(style) - gram_matrix(target))**2)\n",
    "                           for style, target in zip(style_outputs, style_target)])\n",
    "    content_loss = tf.reduce_mean((content_outputs - content_target)**2)\n",
    "    return style_weight * style_loss + content_weight * content_loss\n",
    "\n",
    "# Define the model and save it\n",
    "extractor = get_model()\n",
    "extractor.save('neural_style_transfer_model.h5')\n",
    "print(\"Model saved as 'neural_style_transfer_model.h5'\")\n",
    "\n",
    "# Extract content and style features\n",
    "content_target = extractor(content_image)[-1]\n",
    "style_target = [gram_matrix(output) for output in extractor(style_image)[:-1]]\n",
    "\n",
    "# Generate stylized image\n",
    "generated_image = tf.Variable(content_image, dtype=tf.float32)\n",
    "\n",
    "optimizer = tf.optimizers.Adam(learning_rate=5.0)\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = extractor(generated_image)\n",
    "        loss = compute_loss(outputs, content_target, style_target)\n",
    "    gradients = tape.gradient(loss, generated_image)\n",
    "    optimizer.apply_gradients([(gradients, generated_image)])\n",
    "    generated_image.assign(tf.clip_by_value(generated_image, -1.0, 1.0))  # Clip to MobileNetV2 range\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.numpy()}\")\n",
    "\n",
    "# Save and display results\n",
    "styled_image = deprocess_image(generated_image.numpy())\n",
    "plt.imshow(styled_image)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
